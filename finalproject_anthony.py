# -*- coding: utf-8 -*-
"""FinalProject_Anthony.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JeLigVIT-wUpmyChEUXS-kvqOVqz9M_h

#**Final Project: Music Changes from 1950-2019**

##**Introduction of the data set and data variables**

url = https://www.kaggle.com/datasets/saurabhshahane/music-dataset-1950-to-2019

*Moura, Luan; Fontelles, Emanuel; Sampaio, Vinicius; França, Mardônio (2020), “Music Dataset: Lyrics and Metadata from 1950 to 2019”, Mendeley Data, V3, doi: 10.17632/3t9vbwxgr5.3*

The data was collected via the Spotify Lyrics Genius, where the song lyrics were extracted to find the most frequently appearing words/phrases, excluding common English words, to then identify the relation in a generative probabilistic model for a topic determination, such as violence level or sadness. Moreover, characteristics such as energy were measured by the intensity of the music, in bpm, or instrumentalness consisting of fewer vocals, amongst the other characteristics.
"""

# Import all the required libraries here
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.feature_selection import RFE
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_curve, roc_auc_score, classification_report, confusion_matrix, accuracy_score, f1_score, precision_recall_curve, auc
from sklearn.tree import DecisionTreeClassifier, export_graphviz
from sklearn.ensemble import RandomForestClassifier
import time
import tensorflow.keras as keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.metrics import RootMeanSquaredError

# Mount your google drive
from google.colab import drive
drive.mount('/content/drive')
data_path = "/content/drive/MyDrive/DSC101/Data/"

music = pd.read_csv(data_path+"tcc_ceds_music.csv")
music.head(10)

music.shape

music.info()

"""There are 28 372 observations in the data set, across 30 columns. Considering the columns, the pertain to each respective song's characterists, of artist, release date, genre, length, age, topic, and the various defining attributes, of which measure the song by defining words and/or phrases in the song lyrics.

##**Research Hypotheses**

- The goal is to predict song topics based upon their lyric's sentimental categorizations, using three classification machine learning models: Decision Tree, Random Forest, and Neural Network. Furthermore, a comparative study of the model's performance and selection of the best model will be determined.

##**Data Visualization**
"""

# Import necessary libraries
import matplotlib.pyplot as plt
import pandas as pd

# Set the x-axis and y-axis values
x = music["release_date"]
y = music["energy"]

# Create the line chart
plt.plot(x, y)

# Add a title and labels for the x-axis and y-axis
plt.title("Energy over Time")
plt.xlabel("Release Date")
plt.ylabel("Energy")

# Display the chart
plt.show()

# Import necessary libraries
import seaborn as sns
import pandas as pd

# Select the columns to create the heatmap from
columns = ["release_date", "energy", "danceability", "valence", "loudness"]

# Create a correlation matrix from the selected columns
corr_matrix = music[columns].corr()

# Create the heatmap using the correlation matrix
sns.heatmap(corr_matrix, cmap="coolwarm", annot=True)

# Display the chart
plt.show()

# Import necessary libraries
import matplotlib.pyplot as plt
import pandas as pd

# Get the counts for each category in the "genre" column
genre_counts = music["genre"].value_counts()

# Create the bar chart
plt.bar(genre_counts.index, genre_counts.values)

# Add a title and labels for the x-axis and y-axis
plt.title("Genre Counts")
plt.xlabel("Genre")
plt.ylabel("Count")

# Display the chart
plt.show()

# Import necessary libraries
from wordcloud import WordCloud, STOPWORDS
import matplotlib.pyplot as plt
import pandas as pd

rock = music[music['genre'] == 'rock']

# Create a string of all the lyrics in the dataset
lyrics_text = " ".join(rock["lyrics"])

# Define stopwords
stopwords = set(STOPWORDS)
stopwords.update(["chorus", "verse", "oh", "yeah", "know", "come"])

# Create the word cloud
wordcloud = WordCloud(stopwords=stopwords, background_color="white").generate(lyrics_text)

# Plot the word cloud
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis("off")
plt.title("Top Lyrics for the Rock Genre")
plt.show()

"""##**Data Cleaning & Preprocessing**

### Missing Values
"""

music.drop(columns=['Unnamed: 0', 'lyrics'], inplace=True)
music.isnull().sum()

"""In cleaning the data, there were no unavailable results in the data set, additionally run through to manually search for missing attributes. The variables 'Unnamed' and 'lyrics' were dropped  from the data set, for aesthetic purposes, as they were not variables that would have been likely to use in analysis, other than having already been identifyied their phrases for song feature measurement.

### Factorizing Object Variables
"""

# loop through each column in the DataFrame
for col in music.columns:
    # check if the column is an object type
    if music[col].dtype == 'object':
        # convert the column to a numeric category
        music[col] = music[col].factorize()[0]

"""- The factorization of the object values allows for the normalization of the data to occur, using integer values in place of the variable labels.

##**Models**

### Decision Tree Model
"""

X = music.drop(columns=['topic']).values # input data
y = music['topic'] # response data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
X = pd.DataFrame(X)

dtc = DecisionTreeClassifier(criterion='entropy')
dtc.fit(X_train, y_train)

K= X.shape[1]

accuracy=[]
f1=[]
best_accuracy = 0
best_f1 = 0
best_k = 0

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

lr = LogisticRegression(max_iter=1000)
lr.fit(X_train_scaled, y_train)

for i in range(1,K+1):
  # Out of K x input features select k
  rfe = RFE(estimator=lr, n_features_to_select=i)
  # fit the RFE object to the data
  rfe.fit(X_train_scaled, y_train)

  # select only the selected features
  X_selected = X[X.columns[rfe.support_]]

  X_selected_train, X_selected_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)


  dtc = DecisionTreeClassifier(criterion='entropy')
  dtc.fit(X_selected_train, y_train)

  y_pred = dtc.predict(X_selected_test)
  accuracy.append(accuracy_score(y_test, y_pred))

  f1.append(f1_score(y_test, y_pred, average='weighted'))

  if accuracy[-1] > best_accuracy and f1[-1] > best_f1:
      best_accuracy = accuracy[-1]
      best_f1 = f1[-1]
      best_k = i

print("Best Accuracy: {}".format(best_accuracy))
print("Best F1-Score: {}".format(best_f1))
print("Best Number of Variables: {}".format(best_k))

start_time = time.time()
# the best model so far is with k=15
rfe = RFE(estimator=lr, n_features_to_select=best_k)
# fit the RFE object to the data
rfe.fit(X_train, y_train)

# select only the selected features
X_selected = X[X.columns[rfe.support_]]

X_selected_train, X_selected_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)


dtc = DecisionTreeClassifier(criterion='entropy')
dtc.fit(X_selected_train, y_train)

y_pred = dtc.predict(X_selected_test)
end_time = time.time()

# Evaluate the performance of the model on the test data
cm2=confusion_matrix(y_test, y_pred)
dtc_best_scores=classification_report(y_test, y_pred)
dtc_best_accuracy=accuracy_score(y_test, y_pred)
print(cm2)
print(dtc_best_scores)
print(dtc_best_accuracy)

plt.figure(figsize=(7,7))
sns.heatmap(cm2, annot=True, fmt=".2f", linewidths=.5, square = True, cmap = 'Greens_r');
plt.ylabel('Actual label');
plt.xlabel('Predicted label');
all_sample_title = 'Best Accuracy(Decision Tree Classifier): {:.4f}'.format(dtc_best_accuracy)
plt.title(all_sample_title, size = 15);

dtc_training_time = end_time - start_time
print("Decision Tree Training Time: {} seconds".format(dtc_training_time))

"""#### Area Under the curve"""

# compute the ROC curve and AUC score

y_pred_prob = dtc.predict_proba(X_selected_test)
# calculate ROC curve and AUC score for each class separately
fpr = dict()
tpr = dict()
roc_auc = dict()
n_classes = len(np.unique(y))
for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_test == i, y_pred_prob[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

# plot ROC curve for each class
plt.figure(figsize=(7,7))
colors = ['blue', 'red', 'green', 'orange', 'purple'] # add more colors if needed
for i, color in zip(range(n_classes), colors):
    plt.plot(fpr[i], tpr[i], color=color, lw=2, label='Decision Tree of Class {0} (AUC = {1:.5f})'.format(i, roc_auc[i]))

plt.plot([0, 1], [0, 1], 'k--', lw=2)
plt.xlim([-0.05, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend(loc="lower right")
plt.show()

"""- ROC Curve for the decision tree classifier model saw the machine learning to build to about 74%, indicating a highly effective rate of learning to estimate the variables, rather than random/sparatic guessing in determination.

### Random Forest Model
"""

X = music.drop(columns=['topic']).values # input data
y = music['topic'] # response data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
X = pd.DataFrame(X)
X_train = pd.DataFrame(X_train)
rfc = RandomForestClassifier(n_estimators=20, max_depth=7, min_samples_leaf=5)
rfc.fit(X_train, y_train)

K= X.shape[1]

accuracy=[]
f1=[]
best_accuracy = 0
best_f1 = 0
best_k = 0

for i in range(1,K+1):
  # Out of K x input features select k
  rfe = RFE(estimator=rfc, n_features_to_select=i, step=1)
  # fit the RFE object to the data
  rfe.fit(X_train, y_train)

  # select only the selected features
  X_selected = X[X.columns[rfe.support_]]

  X_selected_train, X_selected_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)

  rfc = RandomForestClassifier(n_estimators=20, max_depth=7, min_samples_leaf=5)
  rfc.fit(X_selected_train, y_train)

  y_pred = rfc.predict(X_selected_test)
  accuracy.append(accuracy_score(y_test, y_pred))

  f1.append(f1_score(y_test, y_pred, average='weighted'))

  if accuracy[-1] > best_accuracy and f1[-1] > best_f1:
    X_selected = X_selected
    best_accuracy = accuracy[-1]
    best_f1 = f1[-1]
    best_k = i

print("Best Accuracy: {}".format(best_accuracy))
print("Best F1-Score: {}".format(best_f1))
print("Best Number of Variables: {}".format(best_k))

start_time = time.time()
# Create an RFE object with 10 features to select
rfe = RFE(estimator=rfc, n_features_to_select=best_k, step=1)
# Fit the RFE object to the training data
rfe.fit(X_train, y_train)

# select only the selected features
X_selected = X[X.columns[rfe.support_]]

X_selected_train, X_selected_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)


# Train the model on the training data
rfc.fit(X_selected_train, y_train)

# Evaluate the performance of the model on the testing data
y_pred = rfc.predict(X_selected_test)
end_time = time.time()

# Evaluate the performance of the model on the test data
cm2=confusion_matrix(y_test, y_pred)
rfc_best_scores=classification_report(y_test, y_pred)
rfc_best_accuracy=rfc.score(X_selected_test, y_test)
print(cm2)
print(rfc_best_scores)
print(rfc_best_accuracy)

plt.figure(figsize=(7,7))
sns.heatmap(cm2, annot=True, fmt=".2f", linewidths=.5, square = True, cmap = 'Greens_r');
plt.ylabel('Actual label');
plt.xlabel('Predicted label');
all_sample_title = 'Best Accuracy(Random Forest Classifier): {:.4f}'.format(rfc_best_accuracy)
plt.title(all_sample_title, size = 15);

rfc_training_time = end_time - start_time
print("Random Forest Training Time: {} seconds".format(rfc_training_time))

"""#### Area Under the curve"""

# compute the ROC curve and AUC score

y_pred_prob = rfc.predict_proba(X_selected_test)
# calculate ROC curve and AUC score for each class separately
fpr = dict()
tpr = dict()
roc_auc = dict()
n_classes = len(np.unique(y))
for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_test == i, y_pred_prob[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

# plot ROC curve for each class
plt.figure(figsize=(7,7))
colors = ['blue', 'red', 'green', 'orange', 'purple'] # add more colors if needed
for i, color in zip(range(n_classes), colors):
    plt.plot(fpr[i], tpr[i], color=color, lw=2, label='Random Forest of Class {0} (AUC = {1:.5f})'.format(i, roc_auc[i]))

plt.plot([0, 1], [0, 1], 'k--', lw=2)
plt.xlim([-0.05, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend(loc="lower right")
plt.show()

"""### Artificial Neural Network"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPRegressor
from sklearn.feature_selection import RFE
from sklearn.metrics import mean_squared_error, r2_score

# Split data into X and y
X = music.drop(columns=['topic']).values
y = music['topic'].values

# Split data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize data
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

from sklearn.neural_network import MLPRegressor

class MyMLPRegressor(MLPRegressor):
    @property
    def feature_importances_(self):
        return np.abs(self.coefs_[0]).sum(axis=1)
    def predict_proba(self, X):
        return self.predict(X).reshape(-1, 1)

# Then, you can use MyMLPRegressor in your code like this:
estimator = MyMLPRegressor(hidden_layer_sizes=(8,), activation='relu', solver='adam', max_iter=1000)


# Define the feature selector
selector = RFE(estimator=estimator, n_features_to_select=5)

# Fit the selector on the training data
selector.fit(X_train_scaled, y_train)

# Get the selected features
selected_features = X_train[:, selector.support_]

# Train the estimator on the selected features
estimator.fit(selected_features, y_train)

# Evaluate the estimator on the test data
y_pred = estimator.predict(X_test[:, selector.support_])
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Test MSE: {mse:.4f}")
print(f"Test R^2 score: {r2:.4f}")

print(f"Test MSE: {mse:.6f}")
print(f"Test R^2 score: {r2:.6f}")
model_training_time = end_time - start_time
print("Neural Network Training Time: {} seconds".format(model_training_time))

"""#### Area Under the curve"""

# compute the ROC curve and AUC score

import pandas as pd
import numpy as np
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_curve, roc_auc_score
import matplotlib.pyplot as plt

# Generate some random data
X, y = make_classification(n_samples=1000, n_classes=2, random_state=42)

# Split data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Fit a logistic regression model on the training data
clf = LogisticRegression()
clf.fit(X_train, y_train)

# Get predicted probabilities for the test data
y_pred_prob = clf.predict_proba(X_test)[:, 1]

# Compute false positive rate, true positive rate, and thresholds
fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)

# Compute AUC score
auc_score = roc_auc_score(y_test, y_pred_prob)

# Plot ROC curve
plt.plot(fpr, tpr)
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title(f'ROC Curve (AUC={auc_score:.6f})')
plt.show()

"""##**Summary & Findings of Project**

Overall, this sample data of songs across genres, for 1950 to 2019, has provides an overarching notion of the popularization of music style trends of the last 70 years, for which my prior research ahs proved the trends of music stylistic choices, in both individual songs and genres as a whole. In this research via regression models to determine song topics based upon their lyrical probability alignment to certain abstract topics of feeling, there may be use in applying such analysis for major music streaming services, such as Spotify or Apple Music. These services tend to output an overall summary of user statistics at the end of each year to show the user their musical preferences. These preferences range from the top artists listened to by the user over the course of the last year, to the genres or mood of the songs they listen to most. This may prove the algorithms used by these companies to be something similar to the classifier regression models, in order to acquire something of a sense on how the music is both measured into abstract sentiments as well as determining the individual user’s specifications based upon their listening history.

It may also be used, in turn, to determine playlists created by the companies that based on certain genres, moods, or decades, based on popularity by number of streams and/or lyrical analysis for topic. These playlists could form such topics as ‘Soft Rock’, ‘Sad 60s’, or ’80s Dance’. For instance, genre and topic interrelationships in separating topic, the pop and country genres hold significance in sadness topic likely due to the pop music of the 1950s consisting more of individual’s pure joy and sorrow, while in the coming years, the genres grow to become more focused upon loneliness, doubt, and heartbreak. While on the other hand, playlists of blues and rock, with their supremacy of the violence topic, find themselves to be more related to rebellious subjects, used in times of protest or among counter-culturalists, gaining great traction in between the 1960s and 70s, often in reaction to things such as the Vietnam War, amidst other historical developments.
"""